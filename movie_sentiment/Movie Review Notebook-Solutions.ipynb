{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today's exercise will be done with [scikit-learn](http://scikit-learn.org/stable/index.html) a very popular python package for Machine Learning. It implements most common ML models and methods for preparing the features. In fact, many companies use it in production.\n",
    "\n",
    "Unless you want to use custom models or neural networks, you will be able to do most of our development with scikit-learn.\n",
    "\n",
    "This notebook will take you through the process of creating a classifier on your own. An example implementation is already filled in to help you get started. \n",
    "\n",
    "The exercises are there to guide you, but feel free to experiment beyond them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Movie Review Model\n",
    "\n",
    "The sections of the notebook will take you through each step of creating a classifier.\n",
    "\n",
    "### Loading the data\n",
    "\n",
    "For this task we will using a real movie review dataset. The dataset contains texts of reviews and a sentiment label (0 = bad, 1=good). Both the train and test sets contain 50\\% of each.  \n",
    "\n",
    "As a reminder, *training data* is used to train/fit your model. *Test data* is used to evaluate performance. We use a separate dataset for evaluation, because it tells us how we will perform on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I felt a great joy, after seeing this film, no...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0  I felt a great joy, after seeing this film, no...          1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('train.data')\n",
    "train_data[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I felt a great joy, after seeing this film, not because it is a master piece, but because it convinced me of, that the Portuguese cinema became really very good. We can see here the best Portuguese actores in this field.\n"
     ]
    }
   ],
   "source": [
    "print(train_data.text.iloc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Henry Thomas showed a restraint, even when the third act turned into horrible hollywood resolution that could've killed this movie, that kept the dignity of a redemption story and as for pure creepiness-sniffing babies?\n"
     ]
    }
   ],
   "source": [
    "print(train_data.text.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This film is pretty good, it actually is like ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0  This film is pretty good, it actually is like ...          1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('test.data')\n",
    "test_data[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is stored in a Pandas DataFrame. \n",
    "\n",
    "To access the columns use `train_data.text` or `train_data.sentiment`.\n",
    "\n",
    "If you are having trouble with it, I've put each column into a separate variable below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = train_data.text.values\n",
    "train_sentiment = train_data.sentiment.values\n",
    "\n",
    "test_test = test_data.text.values\n",
    "test_sentiment = test_data.sentiment.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the features\n",
    "\n",
    "The next step is to create features. Scikit-learn has a couple of different functions to help us:\n",
    "\n",
    "[CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html): Counts the words in a piece of text.\n",
    "\n",
    "[TfidfVectorier](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer): Scaled version of counts - weighs rare words higher\n",
    "\n",
    "Both classes will transform texts to a matrix. Each row in the matrix represents a data point, each column maps to a word. To use this class, first call the `fit` method to create a map from words to indicies. Then call `transform` to actually create the matrix.\n",
    "\n",
    "---\n",
    "\n",
    "**Exercise: Try using binary counts instead of actual counts**\n",
    "\n",
    "`CountVectorizer(binary=True)`\n",
    "\n",
    "**Exercise: Try using the TfidfVectorizer and compare performance**\n",
    "\n",
    "**Exercise: Try different settings for ngram_range - which range is optimal?**\n",
    "\n",
    "Note: n-grams refer to using phrases of length n (e.g 'very cool' is a bigram/2-gram)\n",
    "\n",
    "\n",
    "*Bonus Exercise: The model seems to have a lot of weird words like \"00001\", figure out how to get rid of them*\n",
    "\n",
    "**Answer: Set `min_df` higher - this will ignore words that occured less than n times:**\n",
    "\n",
    "`CountVectorizer(min_df=5)`\n",
    "\n",
    "will ignore words that occured in less than 5 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2000x9621 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 140206 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "vec = TfidfVectorizer(ngram_range=(1, 2), min_df=3)\n",
    "\n",
    "# first call fit - to know which words you are counting\n",
    "vec.fit(train_data.text)\n",
    "\n",
    "# Now create a matrix from the words - the Xs refer to the matrix form\n",
    "X_train = vec.transform(train_data.text)\n",
    "X_test = vec.transform(test_data.text)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing a model\n",
    "\n",
    "Scikit-learn implements a number of different classifiers, you can find all the ones for supervised learning [here](http://scikit-learn.org/stable/supervised_learning.html#supervised-learning).\n",
    "\n",
    "Here are a few simple ones to get you started.\n",
    "\n",
    "- [Perceptron](http://scikit-learn.org/stable/modules/linear_model.html#perceptron)\n",
    "- [K Nearest Neighbors](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier)\n",
    "- [LinearSVC](http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC)\n",
    "- [RandomForest](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
    "- [Multinomial Naive Bayes](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html)\n",
    "\n",
    "For each classifier, the workflow is similar:\n",
    "\n",
    "1. Create classifier and specify parameters\n",
    "2. Call the `fit` method on the training data.\n",
    "3. Call `score` to get accuracy on the test data OR call `predict` to actually get the prediction values.\n",
    "\n",
    "Note: For `fit` and `score`, you will need to pass in both the text matrix and the output. For predict, you will only need to pass in the text matrix.\n",
    "\n",
    "---\n",
    "\n",
    "**Exercise: Try each of the classifiers above and compare the performance**\n",
    "\n",
    "**Exercise: Try changing the \"K\" in the KNN method**\n",
    "\n",
    "`KNeighborsClassifier(n_neighbors=8)`\n",
    "\n",
    "**Exercise: Try changing the number of trees (n_estimators) in the Random Forest Method**\n",
    "\n",
    "`RandomForestClassifier(n_estimators=8)`\n",
    "\n",
    "**Exercise: Try changing the other parameters under Random Forest Method**\n",
    "\n",
    "See parameters defined in the KNN link above.\n",
    "\n",
    "Feel free to experiment with the settings in the other classifiers, but the Random Forest ones are the most intuitive. \n",
    "\n",
    "\n",
    "Each classifier comes with a number of parameters. In practice, these parameters are not set by hand, because it can be hard predict the effects of each one. Instead, the best parameter settings are found automatically through a process called *hyperparameter tuning*. You can read about it [here](http://scikit-learn.org/0.15/auto_examples/randomized_search.html), but it basically means using a script to try a bunch of parameter settings.\n",
    "\n",
    "*Bonus Exercise: Experiment with [Multinomial Naive Bayes](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html) or with the [Bagging Classifier](http://scikit-learn.org/0.15/modules/generated/sklearn.ensemble.BaggingClassifier.html#sklearn.ensemble.BaggingClassifier)*\n",
    "\n",
    "*Bonus Exercise: Create an [ensemble](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html) of your favorite classifiers. (Hint: you pass in the classifiers you want to use)*\n",
    "\n",
    "**Answer below**\n",
    "\n",
    "*Bonus Exercise: Use the link above to automatically try different settings for one of the classifiers*\n",
    "\n",
    "**Answer below** + http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# Perceptron is a very basic linear model\n",
    "clf = LinearSVC()\n",
    "\n",
    "# Specify input than output\n",
    "clf.fit(X_train, train_data.sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we evaluate the accuracy. \n",
    "\n",
    "Use the exercises above to see how different changes affect the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.754\n"
     ]
    }
   ],
   "source": [
    "# Score method outputs the accuracy\n",
    "print(\"Accuracy:\", clf.score(X_test, test_data.sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 0, 0, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the first 10 predictions \n",
    "clf.predict(X_test)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.856\n"
     ]
    }
   ],
   "source": [
    "# Ensemble example\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Meta classifier with three inner ones (the first part of the tuple is just a label)\n",
    "clf = VotingClassifier([('svc', LinearSVC()), \n",
    "                        ('rfc', RandomForestClassifier(n_estimators=30)),\n",
    "                        ('mnb', MultinomialNB())])\n",
    "clf.fit(X_train, train_data.sentiment)\n",
    "\n",
    "print(\"Accuracy:\", clf.score(X_test, test_data.sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anastassia.kornilova/miniconda3/envs/ml_demo/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'min_samples_split': 5, 'n_estimators': 30}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Automatic parameter search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Gridsearch is a wrapper around a classifer and set of parameters\n",
    "# Here we will try different settings for the number of estimators and \n",
    "# the min_samples_split (another param)\n",
    "grid_search = GridSearchCV(RandomForestClassifier(), \n",
    "                            {'n_estimators': [10, 20, 30],\n",
    "                            'min_samples_split': [2, 5, 10]})\n",
    "grid_search.fit(X_train, train_data.sentiment)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.806"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.score(X_test, test_data.sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding performance\n",
    "\n",
    "Accuracy is a good first metric to look at to get a sense of model performance; it, also, let's us compare different parameter settings. However, it does not give us a good insight into why the model works.\n",
    "\n",
    "To get a better understanding, we will analyze is the weight that the model assigns to different words. This is similar to the exercise that we did in the slides. \n",
    "\n",
    "*Note: this analysis will not work with every classifiers.*\n",
    "\n",
    "The weights are stored in the ``clf.coef_[0]`` variable. We can map it to the words as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we want to put the words in the order of the coefficients\n",
    "words_ordered = sorted(vec.vocabulary_.items(), key=operator.itemgetter(1))\n",
    "# Throw out the indicies\n",
    "words_ordered = [x[0] for x in words_ordered]\n",
    "\n",
    "# Get the weights\n",
    "weights = clf.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pair the words with the coefficients and order them by weight\n",
    "word_weights = list(zip(words_ordered, weights))\n",
    "word_weights_sort = sorted(word_weights, key=operator.itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('worst', -45.0),\n",
       " ('boring', -27.0),\n",
       " ('waste', -27.0),\n",
       " ('terrible', -24.0),\n",
       " ('awful', -22.0),\n",
       " ('nothing', -22.0),\n",
       " ('bottom', -21.0),\n",
       " ('lame', -21.0),\n",
       " ('dog', -20.0),\n",
       " ('bad', -19.0)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Not look for the most positive and negative words\n",
    "word_weights_sort[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fun', 16.0),\n",
       " ('amazing', 17.0),\n",
       " ('enjoyed', 18.0),\n",
       " ('everything', 18.0),\n",
       " ('liked', 18.0),\n",
       " ('brilliant', 19.0),\n",
       " ('great', 19.0),\n",
       " ('shows', 19.0),\n",
       " ('excellent', 23.0),\n",
       " ('wonderful', 26.0)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_weights_sort[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations!! You have built your first maching learning model! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

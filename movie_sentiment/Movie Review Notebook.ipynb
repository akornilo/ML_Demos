{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today's exercise will be done with [scikit-learn](http://scikit-learn.org/stable/index.html) a very popular python package for Machine Learning. It implements most common ML models and methods for preparing the features. In fact, many companies use it in production.\n",
    "\n",
    "Unless you want to use custom models or neural networks, you will be able to do most of our development with scikit-learn.\n",
    "\n",
    "This notebook will take you through the process of creating a classifier on your own. An example implementation is already filled in to help you get started. \n",
    "\n",
    "The exercises are there to guide you, but feel free to experiment beyond them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Movie Review Model\n",
    "\n",
    "The sections of the notebook will take you through each step of creating a classifier.\n",
    "\n",
    "### Loading the data\n",
    "\n",
    "For this task we will using a real movie review dataset. The dataset contains texts of reviews and a sentiment label (0 = bad, 1=good). Both the train and test sets contain 50\\% of each.  \n",
    "\n",
    "As a reminder, *training data* is used to train/fit your model. *Test data* is used to evaluate performance. We use a separate dataset for evaluation, because it tells us how we will perform on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I felt a great joy, after seeing this film, no...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0  I felt a great joy, after seeing this film, no...          1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('train.data')\n",
    "train_data[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I felt a great joy, after seeing this film, not because it is a master piece, but because it convinced me of, that the Portuguese cinema became really very good. We can see here the best Portuguese actores in this field.\n"
     ]
    }
   ],
   "source": [
    "print(train_data.text.iloc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Henry Thomas showed a restraint, even when the third act turned into horrible hollywood resolution that could've killed this movie, that kept the dignity of a redemption story and as for pure creepiness-sniffing babies?\n"
     ]
    }
   ],
   "source": [
    "print(train_data.text.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This film is pretty good, it actually is like ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0  This film is pretty good, it actually is like ...          1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('test.data')\n",
    "test_data[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is stored in a Pandas DataFrame. \n",
    "\n",
    "To access the columns use `train_data.text` or `train_data.sentiment`.\n",
    "\n",
    "If you are having trouble with it, I've put each column into a separate variable below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = train_data.text.values\n",
    "train_sentiment = train_data.sentiment.values\n",
    "\n",
    "test_test = test_data.text.values\n",
    "test_sentiment = test_data.sentiment.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the features\n",
    "\n",
    "The next step is to create features. Scikit-learn has a couple of different functions to help us:\n",
    "\n",
    "[CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html): Counts the words in a piece of text.\n",
    "\n",
    "[TfidfVectorier](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer): Scaled version of counts - weighs rare words higher\n",
    "\n",
    "Both classes will transform texts to a matrix. Each row in the matrix represents a data point, each column maps to a word. To use this class, first call the `fit` method to create a map from words to indicies. Then call `transform` to actually create the matrix.\n",
    "\n",
    "---\n",
    "\n",
    "**Exercise: Try using binary counts instead of actual counts**\n",
    "\n",
    "**Exercise: Try using the TfidfVectorizer and compare performance**\n",
    "\n",
    "**Exercise: Try different settings for ngram_range - which range is optimal?**\n",
    "\n",
    "Note: n-grams refer to using phrases of length n (e.g 'very cool' is a bigram/2-gram)\n",
    "\n",
    "\n",
    "*Bonus Exercise: The model seems to have a lot of weird words like \"00001\", figure out how to get rid of them*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2000x10995 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 95913 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "vec = CountVectorizer()\n",
    "\n",
    "# first call fit - to know which words you are counting\n",
    "vec.fit(train_data.text)\n",
    "\n",
    "# Now create a matrix from the words - the Xs refer to the matrix form\n",
    "X_train = vec.transform(train_data.text)\n",
    "X_test = vec.transform(test_data.text)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '00001',\n",
       " '0093638',\n",
       " '01',\n",
       " '02',\n",
       " '07',\n",
       " '10',\n",
       " '100',\n",
       " '1000',\n",
       " '101',\n",
       " '102',\n",
       " '109',\n",
       " '11',\n",
       " '11th',\n",
       " '12',\n",
       " '120',\n",
       " '12th',\n",
       " '13',\n",
       " '13th',\n",
       " '14',\n",
       " '15',\n",
       " '15mins',\n",
       " '16',\n",
       " '16mm',\n",
       " '17',\n",
       " '1800',\n",
       " '1895',\n",
       " '18th',\n",
       " '18year',\n",
       " '19',\n",
       " '1910',\n",
       " '1920',\n",
       " '1920s',\n",
       " '1930',\n",
       " '1931',\n",
       " '1934',\n",
       " '1936',\n",
       " '1938',\n",
       " '1940',\n",
       " '1948',\n",
       " '1950',\n",
       " '1950s',\n",
       " '1959',\n",
       " '1960',\n",
       " '1960s',\n",
       " '1962',\n",
       " '1963',\n",
       " '1964',\n",
       " '1965',\n",
       " '1968',\n",
       " '1970',\n",
       " '1972',\n",
       " '1974',\n",
       " '1976',\n",
       " '1977',\n",
       " '1980',\n",
       " '1980s',\n",
       " '1982',\n",
       " '1983',\n",
       " '1984',\n",
       " '1987',\n",
       " '1988',\n",
       " '1990',\n",
       " '1990s',\n",
       " '1991',\n",
       " '1992',\n",
       " '1993',\n",
       " '1994',\n",
       " '1995',\n",
       " '1996',\n",
       " '1997',\n",
       " '1998',\n",
       " '1999',\n",
       " '19th',\n",
       " '19thc',\n",
       " '1min',\n",
       " '1st',\n",
       " '20',\n",
       " '200',\n",
       " '2000',\n",
       " '2001',\n",
       " '2002',\n",
       " '2003',\n",
       " '2022',\n",
       " '20th',\n",
       " '21',\n",
       " '21st',\n",
       " '22',\n",
       " '227',\n",
       " '23',\n",
       " '230mph',\n",
       " '24',\n",
       " '24th',\n",
       " '25',\n",
       " '250',\n",
       " '25yrs',\n",
       " '27',\n",
       " '27th',\n",
       " '28',\n",
       " '29',\n",
       " '2nd',\n",
       " '30',\n",
       " '300',\n",
       " '3000',\n",
       " '30s',\n",
       " '35',\n",
       " '35mm',\n",
       " '360',\n",
       " '38',\n",
       " '39',\n",
       " '3k',\n",
       " '3rd',\n",
       " '40',\n",
       " '4000',\n",
       " '40s',\n",
       " '42nd',\n",
       " '45',\n",
       " '475',\n",
       " '4th',\n",
       " '50',\n",
       " '50s',\n",
       " '53',\n",
       " '54',\n",
       " '55',\n",
       " '5yrs',\n",
       " '60',\n",
       " '60s',\n",
       " '62',\n",
       " '64',\n",
       " '69',\n",
       " '6th',\n",
       " '70',\n",
       " '70s',\n",
       " '71',\n",
       " '73',\n",
       " '74th',\n",
       " '77',\n",
       " '7th',\n",
       " '80',\n",
       " '80s',\n",
       " '82',\n",
       " '820',\n",
       " '88',\n",
       " '89',\n",
       " '89or',\n",
       " '8p',\n",
       " '8th',\n",
       " '8½',\n",
       " '90',\n",
       " '90s',\n",
       " '911',\n",
       " '94',\n",
       " '95',\n",
       " '97',\n",
       " '98',\n",
       " '99',\n",
       " '9_',\n",
       " '_attack',\n",
       " '_plan',\n",
       " '_real_',\n",
       " '_so_',\n",
       " '_the',\n",
       " '_undertow_',\n",
       " 'abandoned',\n",
       " 'abandonment',\n",
       " 'abduction',\n",
       " 'abductions',\n",
       " 'abhor',\n",
       " 'abhorrent',\n",
       " 'abi',\n",
       " 'abilities',\n",
       " 'ability',\n",
       " 'able',\n",
       " 'ably',\n",
       " 'abominable',\n",
       " 'abomination',\n",
       " 'abortion',\n",
       " 'abound',\n",
       " 'about',\n",
       " 'above',\n",
       " 'abraham',\n",
       " 'abrasive',\n",
       " 'abroad',\n",
       " 'abruptly',\n",
       " 'absence',\n",
       " 'absent',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absolutley',\n",
       " 'absolutly',\n",
       " 'absorbing',\n",
       " 'abstract',\n",
       " 'absurd',\n",
       " 'abuse',\n",
       " 'abused',\n",
       " 'abusive',\n",
       " 'abysmal',\n",
       " 'abysmally',\n",
       " 'abyss',\n",
       " 'academy',\n",
       " 'acadmey',\n",
       " 'accent',\n",
       " 'accented',\n",
       " 'accents',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'accepted',\n",
       " 'access',\n",
       " 'accessible',\n",
       " 'accident',\n",
       " 'accidental',\n",
       " 'accidentally',\n",
       " 'acclaim',\n",
       " 'acclaimed',\n",
       " 'accompanying',\n",
       " 'accomplish',\n",
       " 'accomplished',\n",
       " 'according',\n",
       " 'account',\n",
       " 'accountant',\n",
       " 'accounting',\n",
       " 'accuracy',\n",
       " 'accurate',\n",
       " 'accused',\n",
       " 'ace',\n",
       " 'achieve',\n",
       " 'achieved',\n",
       " 'achieves',\n",
       " 'achieving',\n",
       " 'achilles',\n",
       " 'acknowledged',\n",
       " 'ackroyd',\n",
       " 'acquired',\n",
       " 'acquit',\n",
       " 'acrobatic',\n",
       " 'across',\n",
       " 'act',\n",
       " 'acted',\n",
       " 'acteurs',\n",
       " 'acting',\n",
       " 'action',\n",
       " 'actioner',\n",
       " 'actionpacked',\n",
       " 'actions',\n",
       " 'actionscenes',\n",
       " 'actively',\n",
       " 'activest',\n",
       " 'activists',\n",
       " 'activity',\n",
       " 'actor',\n",
       " 'actores',\n",
       " 'actors',\n",
       " 'actress',\n",
       " 'actresses',\n",
       " 'acts',\n",
       " 'actual',\n",
       " 'actuality',\n",
       " 'actually',\n",
       " 'actualy',\n",
       " 'acually',\n",
       " 'adage',\n",
       " 'adam',\n",
       " 'adams',\n",
       " 'adaptation',\n",
       " 'adapting',\n",
       " 'adaption',\n",
       " 'adcox',\n",
       " 'add',\n",
       " 'added',\n",
       " 'addicted',\n",
       " 'addiction',\n",
       " 'addicts',\n",
       " 'adding',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'addressed',\n",
       " 'addressing',\n",
       " 'adds',\n",
       " 'adept',\n",
       " 'adequately',\n",
       " 'adhering',\n",
       " 'adjust',\n",
       " 'administration',\n",
       " 'admiration',\n",
       " 'admired',\n",
       " 'admission',\n",
       " 'admit',\n",
       " 'admits',\n",
       " 'admitted',\n",
       " 'admittedly',\n",
       " 'ado',\n",
       " 'adolescents',\n",
       " 'adopted',\n",
       " 'adorable',\n",
       " 'adorned',\n",
       " 'adrian',\n",
       " 'adrien',\n",
       " 'adulhood',\n",
       " 'adult',\n",
       " 'adulteries',\n",
       " 'adulthood',\n",
       " 'adults',\n",
       " 'advance',\n",
       " 'advantage',\n",
       " 'advent',\n",
       " 'adventure',\n",
       " 'adventures',\n",
       " 'adversary',\n",
       " 'advertised',\n",
       " 'advertising',\n",
       " 'advice',\n",
       " 'advise',\n",
       " 'advised',\n",
       " 'adviser',\n",
       " 'advisor',\n",
       " 'aero',\n",
       " 'affair',\n",
       " 'affect',\n",
       " 'affected',\n",
       " 'affecting',\n",
       " 'affectionately',\n",
       " 'affects',\n",
       " 'affirming',\n",
       " 'affleck',\n",
       " 'aficionado',\n",
       " 'afraid',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'afroamerican',\n",
       " 'after',\n",
       " 'afterlife',\n",
       " 'afternoon',\n",
       " 'afterwards',\n",
       " 'afterwords',\n",
       " 'ag',\n",
       " 'again',\n",
       " 'against',\n",
       " 'age',\n",
       " 'aged',\n",
       " 'ageing',\n",
       " 'agency',\n",
       " 'agenda',\n",
       " 'agent',\n",
       " 'ages',\n",
       " 'aggresive',\n",
       " 'aggression',\n",
       " 'aggressive',\n",
       " 'aging',\n",
       " 'ago',\n",
       " 'agony',\n",
       " 'agree',\n",
       " 'agreed',\n",
       " 'agreeing',\n",
       " 'ah',\n",
       " 'ahahahahahaaaaa',\n",
       " 'ahead',\n",
       " 'ai',\n",
       " 'aid',\n",
       " 'aida',\n",
       " 'aided',\n",
       " 'aids',\n",
       " 'aileen',\n",
       " 'ailing',\n",
       " 'aim',\n",
       " 'aimed',\n",
       " 'aimlessly',\n",
       " 'ain',\n",
       " 'aint',\n",
       " 'air',\n",
       " 'airplane',\n",
       " 'airplanes',\n",
       " 'airport',\n",
       " 'airwaves',\n",
       " 'aisle',\n",
       " 'aisles',\n",
       " 'akelly',\n",
       " 'akimbo',\n",
       " 'al',\n",
       " 'ala',\n",
       " 'alamo',\n",
       " 'alan',\n",
       " 'alarm',\n",
       " 'alas',\n",
       " 'alba',\n",
       " 'albeit',\n",
       " 'album',\n",
       " 'albums',\n",
       " 'alcatraz',\n",
       " 'alcoholic',\n",
       " 'alda',\n",
       " 'alec',\n",
       " 'alert',\n",
       " 'alex',\n",
       " 'alexander',\n",
       " 'alexanders',\n",
       " 'alexandra',\n",
       " 'alfred',\n",
       " 'algerians',\n",
       " 'alice',\n",
       " 'alicia',\n",
       " 'alien',\n",
       " 'alienating',\n",
       " 'aliens',\n",
       " 'alike',\n",
       " 'alisan',\n",
       " 'alison',\n",
       " 'alive',\n",
       " 'all',\n",
       " 'alleged',\n",
       " 'allegorical',\n",
       " 'allen',\n",
       " 'allende',\n",
       " 'alley',\n",
       " 'allied',\n",
       " 'alligator',\n",
       " 'allow',\n",
       " 'allowed',\n",
       " 'allowing',\n",
       " 'allows',\n",
       " 'ally',\n",
       " 'almighty',\n",
       " 'almodovar',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'alongside',\n",
       " 'alot',\n",
       " 'aloud',\n",
       " 'already',\n",
       " 'alredy',\n",
       " 'alright',\n",
       " 'also',\n",
       " 'alter',\n",
       " 'altered',\n",
       " 'altering',\n",
       " 'alternately',\n",
       " 'alternates',\n",
       " 'altho',\n",
       " 'althogh',\n",
       " 'although',\n",
       " 'altman',\n",
       " 'altogether',\n",
       " 'altough',\n",
       " 'always',\n",
       " 'am',\n",
       " 'amanda',\n",
       " 'amateur',\n",
       " 'amateurish',\n",
       " 'amateurism',\n",
       " 'amateurs',\n",
       " 'amato',\n",
       " 'amazed',\n",
       " 'amazement',\n",
       " 'amazing',\n",
       " 'amazingly',\n",
       " 'amazon',\n",
       " 'amber',\n",
       " 'ambient',\n",
       " 'ambition',\n",
       " 'ambitious',\n",
       " 'amc',\n",
       " 'ameche',\n",
       " 'amelie',\n",
       " 'amenabar',\n",
       " 'amenable',\n",
       " 'america',\n",
       " 'american',\n",
       " 'americana',\n",
       " 'americanized',\n",
       " 'americans',\n",
       " 'amick',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'amount',\n",
       " 'amounts',\n",
       " 'amuse',\n",
       " 'amused',\n",
       " 'amusement',\n",
       " 'amuses',\n",
       " 'amusing',\n",
       " 'amusingly',\n",
       " 'amy',\n",
       " 'an',\n",
       " 'anabel',\n",
       " 'analyses',\n",
       " 'analyzing',\n",
       " 'anatomy',\n",
       " 'anchor',\n",
       " 'ancient',\n",
       " 'and',\n",
       " 'anderson',\n",
       " 'andie',\n",
       " 'andre',\n",
       " 'andrea',\n",
       " 'andreas',\n",
       " 'andrenaline',\n",
       " 'andretti',\n",
       " 'andrew',\n",
       " 'andy',\n",
       " 'angel',\n",
       " 'angeles',\n",
       " 'angelina',\n",
       " 'angelo',\n",
       " 'angels',\n",
       " 'anger',\n",
       " 'angie',\n",
       " 'angle',\n",
       " 'angles',\n",
       " 'anglophile',\n",
       " 'angry',\n",
       " 'angst',\n",
       " 'animal',\n",
       " 'animals',\n",
       " 'animate',\n",
       " 'animated',\n",
       " 'animation',\n",
       " 'animations',\n",
       " 'animatrix',\n",
       " 'anime',\n",
       " 'animitronics',\n",
       " 'anisio',\n",
       " 'aniston',\n",
       " 'ann',\n",
       " 'anna',\n",
       " 'annabel',\n",
       " 'anne',\n",
       " 'annie',\n",
       " 'annoy',\n",
       " 'annoyed',\n",
       " 'annoying',\n",
       " 'annoys',\n",
       " 'annual',\n",
       " 'another',\n",
       " 'anoying',\n",
       " 'answer',\n",
       " 'answers',\n",
       " 'ante',\n",
       " 'anthem',\n",
       " 'anthology',\n",
       " 'anthony',\n",
       " 'anti',\n",
       " 'anticipated',\n",
       " 'anticipation',\n",
       " 'antics',\n",
       " 'antithesis',\n",
       " 'anton',\n",
       " 'antone',\n",
       " 'antonio',\n",
       " 'antony',\n",
       " 'ants',\n",
       " 'antwerp',\n",
       " 'antwone',\n",
       " 'antz',\n",
       " 'anwar',\n",
       " 'any',\n",
       " 'anybody',\n",
       " 'anyhow',\n",
       " 'anymore',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anytime',\n",
       " 'anyway',\n",
       " 'anyways',\n",
       " 'anywhere',\n",
       " 'ap',\n",
       " 'apart',\n",
       " 'apartment',\n",
       " 'ape',\n",
       " 'apes',\n",
       " 'apidistra',\n",
       " 'apiece',\n",
       " 'apocalypse',\n",
       " 'apocalyptic',\n",
       " 'apologize',\n",
       " 'apologizing',\n",
       " 'apology',\n",
       " 'appalled',\n",
       " 'appalling',\n",
       " 'appallingly',\n",
       " 'apparent',\n",
       " 'apparently',\n",
       " 'appeal',\n",
       " 'appealing',\n",
       " 'appeals',\n",
       " 'appear',\n",
       " 'appearance',\n",
       " 'appearances',\n",
       " 'appeared',\n",
       " 'appearing',\n",
       " 'appears',\n",
       " 'apperance',\n",
       " 'applaud',\n",
       " 'apple',\n",
       " 'applied',\n",
       " 'apply',\n",
       " 'appologise',\n",
       " 'appreciate',\n",
       " 'appreciated',\n",
       " 'apprehension',\n",
       " 'approach',\n",
       " 'appropriate',\n",
       " 'approved',\n",
       " 'approx',\n",
       " 'april',\n",
       " 'apt',\n",
       " 'arab',\n",
       " 'arabia',\n",
       " 'arabian',\n",
       " 'arc',\n",
       " 'arcane',\n",
       " 'arduous',\n",
       " 'are',\n",
       " 'area',\n",
       " 'areas',\n",
       " 'aren',\n",
       " 'arghhh',\n",
       " 'arguable',\n",
       " 'arguably',\n",
       " 'argued',\n",
       " 'arguing',\n",
       " 'argument',\n",
       " 'ariel',\n",
       " 'arielle',\n",
       " 'arises',\n",
       " 'arkin',\n",
       " 'arletty',\n",
       " 'arliss',\n",
       " 'arm',\n",
       " 'armageddon',\n",
       " 'armed',\n",
       " 'armies',\n",
       " 'armin',\n",
       " 'armor',\n",
       " 'armour',\n",
       " 'arms',\n",
       " 'army',\n",
       " 'arnald',\n",
       " 'arness',\n",
       " 'arnie',\n",
       " 'arnold',\n",
       " 'around',\n",
       " 'arquette',\n",
       " 'arranged',\n",
       " 'arrangement',\n",
       " 'arrangements',\n",
       " 'array',\n",
       " 'arrested',\n",
       " 'arrived',\n",
       " 'arrives',\n",
       " 'arrogance',\n",
       " 'arrrrrggghhhhhh',\n",
       " 'arse',\n",
       " 'art',\n",
       " 'artful',\n",
       " 'artfully',\n",
       " 'arthouse',\n",
       " 'arthur',\n",
       " 'artificial',\n",
       " 'artist',\n",
       " 'artistic',\n",
       " 'artistry',\n",
       " 'artists',\n",
       " 'arts',\n",
       " 'arty',\n",
       " 'as',\n",
       " 'ashamed',\n",
       " 'ashes',\n",
       " 'ashley',\n",
       " 'asia',\n",
       " 'asian',\n",
       " 'aside',\n",
       " 'asides',\n",
       " 'ask',\n",
       " 'asked',\n",
       " 'asks',\n",
       " 'asleep',\n",
       " 'aspect',\n",
       " 'aspects',\n",
       " 'aspire',\n",
       " 'aspiring',\n",
       " 'ass',\n",
       " 'assassin',\n",
       " 'assassination',\n",
       " 'assassins',\n",
       " 'assaulted',\n",
       " 'asscrap',\n",
       " 'assembles',\n",
       " 'assertion',\n",
       " 'assigned',\n",
       " 'assistant',\n",
       " 'associate',\n",
       " 'associated',\n",
       " 'association',\n",
       " 'assortment',\n",
       " 'assume',\n",
       " 'assumes',\n",
       " 'assuming',\n",
       " 'assylum',\n",
       " 'astaire',\n",
       " 'astonished',\n",
       " 'astonishing',\n",
       " 'astor',\n",
       " 'astounding',\n",
       " 'astronaut',\n",
       " 'at',\n",
       " 'atheist',\n",
       " 'athena',\n",
       " 'athmosphere',\n",
       " 'atlantis',\n",
       " 'atmosphere',\n",
       " 'atmospheric',\n",
       " 'atrocious',\n",
       " 'atrocity',\n",
       " 'attach',\n",
       " 'attached',\n",
       " 'attack',\n",
       " 'attacked',\n",
       " 'attacking',\n",
       " 'attacks',\n",
       " 'attempt',\n",
       " 'attempted',\n",
       " 'attempting',\n",
       " 'attempts',\n",
       " 'attenborough',\n",
       " 'attendant',\n",
       " 'attended',\n",
       " 'attention',\n",
       " 'attentions',\n",
       " 'attire',\n",
       " 'attitude',\n",
       " 'attitudes',\n",
       " 'attorney',\n",
       " 'attract',\n",
       " 'attracted',\n",
       " 'attractions',\n",
       " 'attractive',\n",
       " 'audience',\n",
       " 'audiences',\n",
       " 'audio',\n",
       " 'audrey',\n",
       " 'august',\n",
       " 'auntie',\n",
       " 'auras',\n",
       " 'aussie',\n",
       " 'austen',\n",
       " 'austin',\n",
       " 'australian',\n",
       " 'australians',\n",
       " 'austria',\n",
       " 'auteuil',\n",
       " 'auteur',\n",
       " 'authenticity',\n",
       " 'author',\n",
       " 'authorizes',\n",
       " 'authors',\n",
       " 'authorty',\n",
       " 'autistic',\n",
       " 'autobiographical',\n",
       " 'autobiography',\n",
       " 'automakers',\n",
       " 'automatically',\n",
       " 'automobiles',\n",
       " 'autopilot',\n",
       " 'autumn',\n",
       " 'ava',\n",
       " 'availability',\n",
       " 'available',\n",
       " 'avenging',\n",
       " 'average',\n",
       " 'aviation',\n",
       " 'avoid',\n",
       " 'avoided',\n",
       " 'avoiding',\n",
       " 'awaited',\n",
       " 'awake',\n",
       " 'award',\n",
       " 'awards',\n",
       " 'aware',\n",
       " 'awareness',\n",
       " 'away',\n",
       " 'aways',\n",
       " 'awe',\n",
       " 'awed',\n",
       " 'awefully',\n",
       " 'awes',\n",
       " 'awesome',\n",
       " 'awful',\n",
       " 'awfully',\n",
       " 'awfulness',\n",
       " 'awhile',\n",
       " 'awkward',\n",
       " 'awry',\n",
       " 'awsome',\n",
       " 'axe',\n",
       " 'axis',\n",
       " 'aykroyd',\n",
       " 'b5',\n",
       " 'baaaaaaaaaaaaaad',\n",
       " 'babbitt',\n",
       " 'babe',\n",
       " 'babes',\n",
       " 'babies',\n",
       " 'baby',\n",
       " 'babysitter',\n",
       " 'bacall',\n",
       " 'bach',\n",
       " 'back',\n",
       " 'backdrop',\n",
       " 'background',\n",
       " 'backstage',\n",
       " 'backstory',\n",
       " 'backwards',\n",
       " 'backwoods',\n",
       " 'bacon',\n",
       " 'bad',\n",
       " 'baddddd',\n",
       " 'badly',\n",
       " 'badman',\n",
       " 'badmitton',\n",
       " 'badness',\n",
       " 'baffles',\n",
       " 'bag',\n",
       " 'bagged',\n",
       " 'bailey',\n",
       " 'baked',\n",
       " 'baker',\n",
       " 'bakhtiari',\n",
       " 'balance',\n",
       " 'balanced',\n",
       " 'bald',\n",
       " 'baldwin',\n",
       " 'baldy',\n",
       " 'ball',\n",
       " 'ballad',\n",
       " 'ballads',\n",
       " 'ballerina',\n",
       " 'balloon',\n",
       " 'ballroom',\n",
       " 'baltimore',\n",
       " 'bam',\n",
       " 'banal',\n",
       " 'banana',\n",
       " 'band',\n",
       " 'banded',\n",
       " 'banderas',\n",
       " 'bandit',\n",
       " 'bandits',\n",
       " 'bands',\n",
       " 'bang',\n",
       " 'banished',\n",
       " 'bank',\n",
       " 'banker',\n",
       " 'bankrupt',\n",
       " 'banks',\n",
       " 'banned',\n",
       " 'banner',\n",
       " 'banter',\n",
       " 'banzai',\n",
       " 'baptist',\n",
       " 'bar',\n",
       " 'barbara',\n",
       " 'barbarian',\n",
       " 'barbarians',\n",
       " 'barbie',\n",
       " 'barbra',\n",
       " 'bard',\n",
       " 'bardwork',\n",
       " 'bare',\n",
       " 'barefoot',\n",
       " 'barely',\n",
       " 'barf',\n",
       " 'bargain',\n",
       " 'bargained',\n",
       " 'barks',\n",
       " 'barman',\n",
       " 'barnaby',\n",
       " 'barnes',\n",
       " 'barrel',\n",
       " 'barry',\n",
       " 'barrymore',\n",
       " 'barton',\n",
       " 'bas',\n",
       " 'base',\n",
       " 'baseball',\n",
       " 'based',\n",
       " 'baseketball',\n",
       " 'basement',\n",
       " 'bash',\n",
       " 'bashed',\n",
       " 'bashing',\n",
       " 'basic',\n",
       " 'basically',\n",
       " 'basis',\n",
       " 'basket',\n",
       " 'basketball',\n",
       " 'basks',\n",
       " 'bastard',\n",
       " 'bat',\n",
       " 'bath',\n",
       " 'bathtub',\n",
       " 'batman',\n",
       " 'bats',\n",
       " 'battle',\n",
       " 'battlefield',\n",
       " 'battles',\n",
       " 'batwoman',\n",
       " 'bayless',\n",
       " 'bayliss',\n",
       " 'bb',\n",
       " 'bbc1',\n",
       " 'bbc2',\n",
       " 'bbc3',\n",
       " 'be',\n",
       " 'beach',\n",
       " 'beaches',\n",
       " 'bean',\n",
       " 'beans',\n",
       " 'bear',\n",
       " 'bears',\n",
       " 'beast',\n",
       " 'beasts',\n",
       " 'beat',\n",
       " 'beaten',\n",
       " 'beating',\n",
       " 'beatles',\n",
       " 'beatrice',\n",
       " 'beats',\n",
       " 'beatty',\n",
       " 'beautiful',\n",
       " 'beautifule',\n",
       " 'beautifully',\n",
       " 'beauty',\n",
       " 'became',\n",
       " 'because',\n",
       " 'beckett',\n",
       " 'beckinsale',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'becoming',\n",
       " 'bed',\n",
       " 'been',\n",
       " 'beens',\n",
       " 'beep',\n",
       " 'beer',\n",
       " 'beers',\n",
       " 'bees',\n",
       " 'before',\n",
       " 'beforehand',\n",
       " 'beg',\n",
       " 'began',\n",
       " 'beggar',\n",
       " 'begged',\n",
       " 'begging',\n",
       " 'begin',\n",
       " 'beginners',\n",
       " 'beginning',\n",
       " 'begins',\n",
       " 'begley',\n",
       " 'begs',\n",
       " 'begun',\n",
       " 'behalf',\n",
       " 'behave',\n",
       " 'behaves',\n",
       " 'behavior',\n",
       " 'behaviour',\n",
       " 'beheaded',\n",
       " 'behind',\n",
       " 'behr',\n",
       " 'beiderbecke',\n",
       " 'being',\n",
       " 'bela',\n",
       " 'beleive',\n",
       " 'beleiving',\n",
       " 'belief',\n",
       " 'believability',\n",
       " 'believable',\n",
       " 'believe',\n",
       " 'believed',\n",
       " 'believers',\n",
       " 'believes',\n",
       " 'belive',\n",
       " 'bell',\n",
       " 'belle',\n",
       " 'bellini',\n",
       " 'bello',\n",
       " 'bellum',\n",
       " 'belly',\n",
       " 'belong',\n",
       " 'belonged',\n",
       " 'belongs',\n",
       " 'beloved',\n",
       " 'below',\n",
       " 'belt',\n",
       " 'belush',\n",
       " 'belushi',\n",
       " 'bemused',\n",
       " 'ben',\n",
       " 'beneath',\n",
       " 'benefits',\n",
       " ...]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can look at the words the vectorizer found like this:\n",
    "vec.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing a model\n",
    "\n",
    "Scikit-learn implements a number of different classifiers, you can find all the ones for supervised learning [here](http://scikit-learn.org/stable/supervised_learning.html#supervised-learning).\n",
    "\n",
    "Here are a few simple ones to get you started.\n",
    "\n",
    "- [Perceptron](http://scikit-learn.org/stable/modules/linear_model.html#perceptron)\n",
    "- [K Nearest Neighbors](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestNeighbors.html)\n",
    "- [LinearSVC](http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html#sklearn.svm.LinearSVC)\n",
    "- [RandomForest](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
    "- [Multinomial Naive Bayes](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html)\n",
    "\n",
    "For each classifier, the workflow is similar:\n",
    "\n",
    "1. Create classifier and specify parameters\n",
    "2. Call the `fit` method on the training data.\n",
    "3. Call `score` to get accuracy on the test data OR call `predict` to actually get the prediction values.\n",
    "\n",
    "Note: For `fit` and `score`, you will need to pass in both the text matrix and the output. For predict, you will only need to pass in the text matrix.\n",
    "\n",
    "---\n",
    "\n",
    "**Exercise: Try each of the classifiers above and compare the performance**\n",
    "\n",
    "**Exercise: Try changing the \"K\" in the KNN method**\n",
    "\n",
    "**Exercise: Try changing the number of trees (n_estimators) in the Random Forest Method**\n",
    "\n",
    "**Exercise: Try changing the other parameters under Random Forest Method**\n",
    "\n",
    "Feel free to experiment with the settings in the other classifiers, but the Random Forest ones are the most intuitive. \n",
    "\n",
    "\n",
    "Each classifier comes with a number of parameters. In practice, these parameters are not set by hand, because it can be hard predict the effects of each one. Instead, the best parameter settings are found automatically through a process called *hyperparameter tuning*. You can read about it [here](http://scikit-learn.org/0.15/auto_examples/randomized_search.html), but it basically means using a script to try a bunch of parameter settings.\n",
    "\n",
    "*Bonus Exercise: Experiment with [Multinomial Naive Bayes](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html) or with the [Bagging Classifier](http://scikit-learn.org/0.15/modules/generated/sklearn.ensemble.BaggingClassifier.html#sklearn.ensemble.BaggingClassifier)*\n",
    "\n",
    "*Bonus Exercise: Create an [ensemble](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html) of your favorite classifiers. (Hint: you pass in the classifiers you want to use)*\n",
    "\n",
    "*Bonus Exercise: Use the link above to automatically try different settings for one of the classifiers*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
       "      fit_intercept=True, max_iter=None, n_iter=None, n_iter_no_change=5,\n",
       "      n_jobs=None, penalty=None, random_state=0, shuffle=True, tol=None,\n",
       "      validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "# Perceptron is a very basic linear model\n",
    "clf = Perceptron()\n",
    "\n",
    "# Specify input than output\n",
    "clf.fit(X_train, train_data.sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we evaluate the accuracy. \n",
    "\n",
    "Use the exercises above to see how different changes affect the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.758\n"
     ]
    }
   ],
   "source": [
    "# Score method outputs the accuracy\n",
    "print(\"Accuracy:\", clf.score(X_test, test_data.sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 0, 0, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the first 10 predictions \n",
    "clf.predict(X_test)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding performance\n",
    "\n",
    "Accuracy is a good first metric to look at to get a sense of model performance; it, also, let's us compare different parameter settings. However, it does not give us a good insight into why the model works.\n",
    "\n",
    "To get a better understanding, we will analyze is the weight that the model assigns to different words. This is similar to the exercise that we did in the slides. \n",
    "\n",
    "*Note: this analysis will not work with every classifiers.*\n",
    "\n",
    "The weights are stored in the ``clf.coef_[0]`` variable. We can map it to the words as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we want to put the words in the order of the coefficients\n",
    "words_ordered = sorted(vec.vocabulary_.items(), key=operator.itemgetter(1))\n",
    "# Throw out the indicies\n",
    "words_ordered = [x[0] for x in words_ordered]\n",
    "\n",
    "# Get the weights\n",
    "weights = clf.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pair the words with the coefficients and order them by weight\n",
    "word_weights = list(zip(words_ordered, weights))\n",
    "word_weights_sort = sorted(word_weights, key=operator.itemgetter(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('worst', -45.0),\n",
       " ('boring', -27.0),\n",
       " ('waste', -27.0),\n",
       " ('terrible', -24.0),\n",
       " ('awful', -22.0),\n",
       " ('nothing', -22.0),\n",
       " ('bottom', -21.0),\n",
       " ('lame', -21.0),\n",
       " ('dog', -20.0),\n",
       " ('bad', -19.0)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Not look for the most positive and negative words\n",
    "word_weights_sort[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fun', 16.0),\n",
       " ('amazing', 17.0),\n",
       " ('enjoyed', 18.0),\n",
       " ('everything', 18.0),\n",
       " ('liked', 18.0),\n",
       " ('brilliant', 19.0),\n",
       " ('great', 19.0),\n",
       " ('shows', 19.0),\n",
       " ('excellent', 23.0),\n",
       " ('wonderful', 26.0)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_weights_sort[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations!! You have built your first maching learning model! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
